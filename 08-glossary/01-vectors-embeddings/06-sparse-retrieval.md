# Sparse Retrieval / BM25 / Lexical Search

## Quick Definition

Traditionelle Keyword-basierte Suche mit **exakten Term-Matches** - schnell, explainbar, aber ohne semantisches Verst√§ndnis.

**Kategorie:** Vectors & Embeddings
**Schwierigkeit:** Beginner
**Aliases:** Sparse Retrieval, BM25, Lexical Search, Keyword Search, Term-based Retrieval

---

## üß† Detaillierte Erkl√§rung

### Intuitive Erkl√§rung

**Sparse Retrieval** funktioniert wie eine klassische Suchmaschine:
- Z√§hle **gemeinsame Keywords** zwischen Query und Dokument
- Gewichte wichtige W√∂rter h√∂her (seltene W√∂rter = wichtiger)
- Ranke Dokumente nach Keyword-Score

**Beispiel:**
```
Query:    "Labork√ºhlschrank defekt"
Dokument: "Der Labork√ºhlschrank ist defekt"

Gemeinsame Keywords: ["Labork√ºhlschrank", "defekt"] ‚Üí 2/2 = 100% Match ‚úÖ
```

**Aber:**
```
Query:    "Labork√ºhlschrank defekt"
Dokument: "K√ºhlschrank im Labor kaputt"

Gemeinsame Keywords: [] ‚Üí 0% Match ‚ùå (trotz gleicher Bedeutung!)
```

**"Sparse"** weil: Nur wenige Dimensionen sind "aktiv" (vorhandene Keywords), Rest = 0.

### Mathematische Formalisierung

**BM25 (Best Matching 25)** ist der Standard-Algorithmus f√ºr Sparse Retrieval:

$$\text{BM25}(q, d) = \sum_{t \in q} \text{IDF}(t) \cdot \frac{f(t, d) \cdot (k_1 + 1)}{f(t, d) + k_1 \cdot \left(1 - b + b \cdot \frac{|d|}{\text{avgdl}}\right)}$$

**Komponenten:**

1. **$f(t, d)$**: Term Frequency - Wie oft kommt Keyword $t$ in Dokument $d$ vor?
2. **$\text{IDF}(t)$**: Inverse Document Frequency - Wie selten ist $t$ in allen Dokumenten?
   $$\text{IDF}(t) = \log\left(\frac{N - n(t) + 0.5}{n(t) + 0.5} + 1\right)$$
   - $N$: Anzahl aller Dokumente
   - $n(t)$: Anzahl Dokumente mit Term $t$

3. **$|d|$**: Dokumentl√§nge (Anzahl W√∂rter)
4. **$\text{avgdl}$**: Durchschnittliche Dokumentl√§nge

**Parameter:**
- **$k_1$**: Term Frequency S√§ttigung (typisch: 1.2-2.0)
- **$b$**: L√§ngen-Normalisierung (typisch: 0.75)

**Intuition:**
- **Seltene W√∂rter** (hohes IDF) = wichtiger
- **H√§ufige W√∂rter** im Dokument (hohes TF) = relevanter
- **L√§ngere Dokumente** werden normalisiert (nicht bevorzugt)

### Why It Matters

**1. Baseline f√ºr Retrieval**

BM25 ist der **Standard-Baseline** f√ºr alle Retrieval-Evaluationen:
- Einfach zu implementieren
- Keine Training n√∂tig
- Oft √ºberraschend gut!

**Benchmark:** In vielen Evaluations (BEIR, MS MARCO) schl√§gt BM25 sogar einfache Dense Retrieval Modelle.

**2. Exakte Keyword-Matches**

Wenn exakte Terme wichtig sind, ist BM25 √ºberlegen:

| Use-Case | BM25 | Dense Retrieval |
|----------|------|-----------------|
| **Produktnummern** ("SKU-12345") | ‚úÖ Findet exakt | ‚ùå Embedding ungenau |
| **Namen** ("Dr. M√ºller") | ‚úÖ Findet exakt | ‚ö†Ô∏è Kann Varianten finden |
| **IDs** ("Ticket-9876") | ‚úÖ Perfekt | ‚ùå Nicht trainiert daf√ºr |
| **Fachbegriffe** (out-of-domain) | ‚úÖ Keyword reicht | ‚ùå Embedding kennt Begriff nicht |

**3. Explainability**

BM25-Scores sind **nachvollziehbar**:
```python
# Warum wurde dieses Dokument gerankt?
# ‚Üí Weil "Labork√ºhlschrank" 3√ó vorkommt (hohes TF)
# ‚Üí Und "defekt" selten ist (hohes IDF)
```

Dense Retrieval: "Embedding-√Ñhnlichkeit 0.87" (Blackbox!)

**4. Keine Trainingskosten**

- **BM25**: Funktioniert sofort auf jedem Datensatz
- **Dense**: Braucht vortrainiertes Embedding-Modell (oder Fine-Tuning)

### Common Variations

**1. BM25** (Standard)
- Wie oben beschrieben
- Parameter: $k_1 = 1.5$, $b = 0.75$

**2. TF-IDF** (√§lter, einfacher)
$$\text{TF-IDF}(t, d) = f(t, d) \cdot \log\left(\frac{N}{n(t)}\right)$$

- Keine S√§ttigung, keine L√§ngen-Normalisierung
- BM25 ist fast immer besser!

**3. BM25+** (Variante)
- Zus√§tzlicher Term f√ºr Dokument-Frequenz
- Minimal bessere Ergebnisse (~1-2%)

**4. BM25F** (f√ºr strukturierte Dokumente)
- Gewichtet verschiedene Felder unterschiedlich
- Beispiel: Titel wichtiger als Body

```python
score = 0.7 √ó BM25(query, title) + 0.3 √ó BM25(query, body)
```

---

## üíª Code-Beispiel

```python
from rank_bm25 import BM25Okapi
import numpy as np

# 1. Dokumente (tokenisiert)
documents = [
    "Der Labork√ºhlschrank ist defekt und muss repariert werden".split(),
    "Das Serverrack im Rechenzentrum ist √ºberhitzt".split(),
    "Die Kaffeemaschine im Pausenraum ist kaputt".split(),
    "Der K√ºhlschrank im Labor funktioniert nicht mehr".split(),
    "Die Klimaanlage im B√ºro ist ausgefallen".split()
]

# 2. BM25 Index erstellen
bm25 = BM25Okapi(documents)

# 3. Query
query = "Labork√ºhlschrank kaputt".split()

# 4. Scores berechnen
scores = bm25.get_scores(query)
print(f"BM25 Scores: {scores}")

# 5. Top-K Ranking
top_k = 3
top_indices = np.argsort(scores)[::-1][:top_k]

print(f"\nüîç BM25 Results f√ºr '{' '.join(query)}':")
for rank, idx in enumerate(top_indices, 1):
    doc_text = ' '.join(documents[idx])
    print(f"{rank}. Score: {scores[idx]:.3f} | {doc_text}")

# 6. Vergleich: Dense Retrieval w√ºrde finden
print("\nüí° Dense Retrieval w√ºrde zus√§tzlich finden:")
print("   'K√ºhlschrank im Labor funktioniert nicht' (semantisch √§hnlich)")
```

**Output:**
```
BM25 Scores: [2.134 0.    0.    0.    0.   ]

üîç BM25 Results f√ºr 'Labork√ºhlschrank kaputt':
1. Score: 2.134 | Der Labork√ºhlschrank ist defekt und muss repariert werden
2. Score: 0.000 | Das Serverrack im Rechenzentrum ist √ºberhitzt
3. Score: 0.000 | Die Kaffeemaschine im Pausenraum ist kaputt

üí° Dense Retrieval w√ºrde zus√§tzlich finden:
   'K√ºhlschrank im Labor funktioniert nicht' (semantisch √§hnlich)
```

**Beobachtung:**
- BM25 findet **nur** Dokument mit exaktem Keyword "Labork√ºhlschrank"
- "K√ºhlschrank im Labor" (semantisch identisch) ‚Üí Score 0.0 ‚ùå
- Dense Retrieval h√§tte beide gefunden ‚úÖ

---

## üîó Related Terms

### **Alternative**
- **[Dense Retrieval](05-dense-retrieval.md)**: Semantisch, Embedding-basiert
- **[Hybrid Search](../04-rag-concepts/03-hybrid-search.md)**: BM25 + Dense kombiniert

### **Verwandt**
- **TF-IDF**: √Ñltere Variante von BM25
- **Inverted Index**: Datenstruktur f√ºr schnelle Keyword-Suche
- **Tokenization**: Text ‚Üí Keywords (wichtig f√ºr BM25!)

### **Baut darauf auf**
- **Query Expansion**: Synonyme zu Query hinzuf√ºgen (verbessert BM25)
- **Re-Ranking**: BM25 f√ºr First-Pass, dann Dense Re-Ranking

---

## üìç Where This Appears

### **Primary Chapter**
- `04-advanced/01-retrieval-methods.md` (Sektion 2) - Sparse Retrieval im Detail
- `06-applications/02-search-systems.md` (Sektion 1) - BM25 Implementierung

### **Usage Examples**
- `06-applications/01-rag-systems.md` (Sektion 3) - BM25 in Hybrid RAG
- `04-advanced/02-retrieval-optimization.md` - BM25 + Dense kombinieren

### **Comparison**
- `03-core/03-evaluation/02-ai-evaluation/03-retrieval-metrics.md` - BM25 als Baseline

---

## ‚ö†Ô∏è Common Misconceptions

### ‚ùå "BM25 ist veraltet, Dense Retrieval ist immer besser"
**Falsch!** BM25 hat klare Vorteile:

**BM25 gewinnt:**
- ‚úÖ Exakte IDs, Produktnummern, Namen
- ‚úÖ Out-of-domain Begriffe (nicht in Embedding-Training)
- ‚úÖ Keine GPU/Model-Inferenz n√∂tig
- ‚úÖ Explainable Ranking

**Dense gewinnt:**
- ‚úÖ Semantische Suche (Synonyme, Konzepte)
- ‚úÖ Multilingual Search
- ‚úÖ Typo-Robustheit

**Best Practice:** **Hybrid Search** (BM25 + Dense) f√ºr beste Ergebnisse!

**BEIR Benchmark (Durchschnitt √ºber 18 Datasets):**
```
BM25:          0.420 NDCG@10
Dense (E5):    0.512 NDCG@10  (+22%)
Hybrid:        0.547 NDCG@10  (+30% vs. BM25, +7% vs. Dense)
```

### ‚ùå "BM25 braucht keine Preprocessing"
**Falsch!** Qualit√§t h√§ngt stark von Tokenization ab:

**Schlechtes Preprocessing:**
```python
doc = "Labork√ºhlschrank"
tokens = doc.split()  # ["Labork√ºhlschrank"]

query = "K√ºhlschrank Labor"
tokens_q = query.split()  # ["K√ºhlschrank", "Labor"]

# Kein Match! ‚ùå
```

**Gutes Preprocessing:**
```python
# Lowercase + Stemming
doc = "labork√ºhlschrank" ‚Üí stem("labor") + stem("k√ºhlschrank")
query = "k√ºhlschrank labor" ‚Üí stem("k√ºhlschrank") + stem("labor")

# Match! ‚úÖ
```

**Empfohlene Pipeline:**
1. Lowercase
2. Remove Stopwords ("der", "die", "das")
3. Stemming/Lemmatization (optional)
4. Tokenization

### ‚ùå "BM25 ist langsamer als Dense Retrieval"
**Genau umgekehrt!**

**Latenz (1M Dokumente):**
```
BM25 (Inverted Index):    5-10ms   ‚Üê Sehr schnell!
Dense (HNSW ANN):         10-50ms  ‚Üê Langsamer (aber semantisch besser)
Dense (Exact Search):     1000+ms  ‚Üê Extrem langsam ohne Index
```

**Warum BM25 schnell ist:**
- **Inverted Index**: Mapping von Keyword ‚Üí Dokument-IDs
- Nur Dokumente mit Query-Keywords werden gepr√ºft
- Keine Embedding-Inferenz n√∂tig

**Dense Retrieval:**
- Muss Embedding-Modell ausf√ºhren (GPU!)
- ANN-Search (HNSW) auch mit Index langsamer als BM25

---

## üìä BM25 Parameters Tuning

**Standard-Parameter:**
- $k_1 = 1.5$ (Term Frequency S√§ttigung)
- $b = 0.75$ (L√§ngen-Normalisierung)

**Parameter-Effekte:**

| Parameter | Niedrig | Hoch | Empfehlung |
|-----------|---------|------|------------|
| **$k_1$** | TF z√§hlt weniger | TF z√§hlt mehr | 1.2-2.0 (kurze Docs: niedriger) |
| **$b$** | L√§nge egal | L√§nge wichtig | 0.75 (Standard) |

**Tuning-Beispiel:**
```python
from rank_bm25 import BM25Okapi

# Custom Parameters
bm25_tuned = BM25Okapi(documents, k1=1.2, b=0.75)

# Standard
bm25_standard = BM25Okapi(documents)  # k1=1.5, b=0.75
```

**Empfehlung:** Standard-Parameter funktionieren in 90% der F√§lle gut. Nur bei spezifischen Problemen tunen.

---

## üéØ Zusammenfassung

**Ein Satz:** BM25 ist Keyword-basierte Suche mit TF-IDF, die exakte Matches findet, aber semantisches Verst√§ndnis fehlt.

**Formel (vereinfacht):**
$$\text{BM25} \approx \sum \text{IDF}(t) \cdot \text{TF}(t, d)_{\text{saturated}}$$

**Key Takeaways:**
1. **Exakt**: Findet exakte Keywords (IDs, Namen, Produktnummern)
2. **Schnell**: 5-10ms Latenz mit Inverted Index
3. **Explainable**: Score basiert auf sichtbaren Keywords
4. **Baseline**: Standard f√ºr Retrieval-Evaluation
5. **Hybrid**: Kombiniert mit Dense f√ºr beste Ergebnisse

**Wann nutzen?**
- ‚úÖ Exakte Keyword-Matches wichtig
- ‚úÖ Out-of-domain Begriffe (nicht in Embedding-Training)
- ‚úÖ Schnelle Latenz erforderlich
- ‚úÖ Explainable Ranking n√∂tig
- ‚ùå Semantische Suche (Synonyme) ‚Üí Dense Retrieval
- ‚ùå Multilingual ‚Üí Dense Retrieval

**Best Practice:** **Hybrid Search** (BM25 + Dense) nutzt St√§rken beider Methoden!

---

**Navigation:**
- üè† [Zur√ºck zur Kategorie](00-overview.md)
- ‚¨ÖÔ∏è [Vorheriger Begriff: Dense Retrieval](05-dense-retrieval.md)
- ‚û°Ô∏è [N√§chste Kategorie: Transformers & Attention](../02-transformers-attention/)
