# Similarity Measures

## üéØ Lernziele
- Verstehe verschiedene Similarity-Metriken f√ºr Embeddings
- Lerne wann welche Metrik zu verwenden ist
- Verstehe die Performance-Implications verschiedener Metriken
- Lerne praktische Implementierung in RAG-Systemen

## üìñ Geschichte & Kontext
Similarity-Measures sind das Herzst√ºck jeder Suchmaschine und RAG-Systems. Die Wahl der richtigen Metrik entscheidet dar√ºber, welche Dokumente als relevant erkannt werden. Von einfachen Keyword-Matching bis zu modernen Embedding-Similarity haben sich diese Metriken stetig weiterentwickelt.

## üßÆ Theorie

## 1. Cosine Similarity ‚≠ê

**Definition:** Misst den Winkel zwischen zwei Vektoren (0¬∞ = identisch, 90¬∞ = orthogonal)

**Formel:**
```
cos(Œ∏) = (a ¬∑ b) / (|a| * |b|)
Range: [-1, 1], meist [0, 1] bei Embeddings
```

**Code:**
```python
# sklearn
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity([query_emb], embeddings)[0]

# sentence-transformers
from sentence_transformers import util
similarity = util.cos_sim(query_emb, embeddings)[0]

# numpy (wenn normalisiert)
similarity = embeddings @ query_emb  # Dot product = Cosine!
```

**Interpretation:**
- `> 0.8`: Sehr √§hnlich
- `0.6 - 0.8`: √Ñhnlich
- `0.4 - 0.6`: Schwach √§hnlich
- `< 0.4`: Un√§hnlich

**Wann nutzen?**
- ‚úÖ Standard f√ºr Semantic Search
- ‚úÖ Unabh√§ngig von Vektor-L√§nge
- ‚úÖ Development/Testing (explizit, klar)
- ‚ùå Etwas langsamer als Dot Product

**Target:** Relevante Chunks sollten > 0.6 Similarity haben

---

## 2. Dot Product

**Definition:** Summe der elementweisen Multiplikation zweier Vektoren

**Formel:**
```
a ¬∑ b = Œ£(a[i] * b[i])
Range: [-‚àû, +‚àû]
Wenn normalisiert: identisch zu Cosine Similarity
```

**Code:**
```python
# numpy
import numpy as np

# Empfohlen: @ operator
scores = embeddings @ query_emb

# Alternative: np.dot
scores = np.dot(embeddings, query_emb)
```

**Interpretation:**
- H√∂herer Score = √§hnlicher
- Nur zuverl√§ssig wenn Embeddings normalisiert sind
- Dann: identisch zu Cosine (aber schneller!)

**Wann nutzen?**
- ‚úÖ **Production RAG** (schnellste Methode)
- ‚úÖ Wenn Embeddings normalisiert sind
- ‚úÖ Gro√üe Datenmengen (Millionen Vektoren)
- ‚ö†Ô∏è Nur mit Normalisierung zuverl√§ssig

**Target:** Normalisierung aktivieren: `model.encode(..., normalize_embeddings=True)`

---

## 3. Euclidean Distance (L2)

**Definition:** Geradlinige Distanz zwischen zwei Punkten im Vektorraum

**Formel:**
```
dist = ‚àö(Œ£(a[i] - b[i])¬≤)
Range: [0, ‚àû], 0 = identisch
```

**Code:**
```python
# sklearn
from sklearn.metrics.pairwise import euclidean_distances
distances = euclidean_distances([query_emb], embeddings)[0]

# numpy
distances = np.linalg.norm(embeddings - query_emb, axis=1)

# Zu Similarity konvertieren
similarities = 1 / (1 + distances)
```

**Interpretation:**
- Kleinere Distance = √§hnlicher
- Misst absolute Position im Raum
- Geometrisch intuitiv (Luftlinie)

**Wann nutzen?**
- ‚úÖ Clustering (K-Means nutzt Euclidean)
- ‚úÖ Visualisierung (geometrisch intuitiv)
- ‚úÖ Wenn Magnitude wichtig ist
- ‚ùå Nicht Standard f√ºr Semantic Search

**Target:** Nur f√ºr spezielle Use Cases, nicht f√ºr regul√§res Retrieval

---

## 4. Manhattan Distance (L1)

**Definition:** Summe der absoluten Differenzen (Taxicab-Metrik)

**Formel:**
```
dist = Œ£|a[i] - b[i]|
Range: [0, ‚àû]
```

**Code:**
```python
# sklearn
from sklearn.metrics.pairwise import manhattan_distances
distances = manhattan_distances([query_emb], embeddings)[0]

# numpy
distances = np.sum(np.abs(embeddings - query_emb), axis=1)
```

**Interpretation:**
- "Stadtstrecke" statt Luftlinie
- Robust gegen Outlier-Dimensionen
- Kleinere Distance = √§hnlicher

**Wann nutzen?**
- ‚úÖ Sparse, hochdimensionale Vektoren
- ‚úÖ Robustness gegen Outliers wichtig
- ‚ùå Sehr selten in RAG verwendet

**Target:** Nische - nur f√ºr spezifische Anforderungen

---

## üìä Vergleich: Wann welche Similarity?

| Methode | Speed | Normalisierung n√∂tig? | Use Case |
|---------|-------|----------------------|----------|
| **Dot Product** | ‚ö°‚ö°‚ö° Fastest | Ja (sonst unzuverl√§ssig) | **Production RAG** (Standard) |
| **Cosine Similarity** | ‚ö°‚ö° Fast | Nein | Development/Testing |
| **Euclidean** | ‚ö° Slower | Nein | Clustering, Visualisierung |
| **Manhattan** | ‚ö° Slower | Nein | Sparse Data, Robustness |

**Empfehlung f√ºr RAG:**
```python
# In Production:
scores = embeddings @ query_emb  # Dot product (schnell)

# Voraussetzung:
model.encode(..., normalize_embeddings=True)
```

## üìä Vergleiche & Varianten

### Performance-Vergleich (1M Embeddings)
- **Dot Product**: ~10ms (GPU), ~50ms (CPU)
- **Cosine Similarity**: ~15ms (GPU), ~80ms (CPU)
- **Euclidean Distance**: ~20ms (GPU), ~120ms (CPU)

### Similarity vs Distance Conversion
```python
# Distance zu Similarity
similarity = 1 / (1 + distance)  # F√ºr Euclidean/Manhattan
similarity = 1 - (distance / max_distance)  # Normalisiert

# Similarity zu Distance
distance = np.sqrt(2 * (1 - similarity))  # F√ºr Cosine
```

### Framework-spezifische Optimierungen
- **FAISS**: Optimierte IP (Inner Product) und L2 Distance
- **ChromaDB**: Standard Cosine, mit IP-Option
- **Weaviate**: Cosine als Standard, Dot als Option

## üéì Weiterf√ºhrende Themen

### Original Papers
- [A Study of Cross-Encoder and Bi-Encoder Architectures](https://arxiv.org/abs/1908.10084) - Reimers & Gurevych
- [Efficient Vector Similarity Computation](https://arxiv.org/abs/1909.12095) - FAISS Technical Paper

### Verwandte Kapitel
- [../embeddings/01-FUNDAMENTALS.md](../../05-embeddings/01-FUNDAMENTALS.md) - Embedding-Grundlagen
- [03-ranking-metrics.md](03-ranking-metrics.md) - Ranking-Evaluation f√ºr RAG
- [../infrastructure/03-vector-databases.md](../infrastructure/03-vector-databases.md) - Production Similarity

### N√§chste Schritte im Lernpfad
1. **F√ºr RAG-Entwicklung**: [03-ranking-metrics.md](03-ranking-metrics.md)
2. **F√ºr Production**: [../infrastructure/03-vector-databases.md](../infrastructure/03-vector-databases.md)
3. **F√ºr Advanced Retrieval**: [../../advanced/01-retrieval-methods.md](../../advanced/01-retrieval-methods.md)

## üìö Ressourcen

### Wissenschaftliche Papers
- [Vector Similarity Search](https://arxiv.org/abs/1909.12095) - FAISS Documentation
- [Sentence-BERT Evaluation](https://arxiv.org/abs/1908.10084) - Similarity Benchmarks

### Blog Posts & Tutorials
- [Cosine vs Dot Product](https://blog.reachsumit.com/posts/2019/cosine-vs-dot/) - Detailed Comparison
- [FAISS Index Guide](https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index) - Production Similarity

### Videos & Talks
- [Vector Search Explained](https://www.youtube.com/watch?v=QvKMwLjdK-s) - Weaviate Tutorial

### Interaktive Demos
- [Vector Similarity Calculator](https://colab.research.google.com/drive/1eGzCrY1dE_fZ7VhY8H-v-n3K9s_xmwuN) - Try Different Metrics
